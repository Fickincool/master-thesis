{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a91f76e2-5ad5-469c-9f2b-2fafbb4666bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomoSegmentPipeline.utils.common import read_array, write_array\n",
    "from tomoSegmentPipeline.utils import setup\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import mrcfile\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from glob import glob\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import normalized_mutual_information as nmi\n",
    "from scipy import ndimage\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "PARENT_PATH = setup.PARENT_PATH\n",
    "ISONET_PATH = os.path.join(PARENT_PATH, 'data/isoNet/')\n",
    "\n",
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43c26091-73d1-4eff-9074-4dcc1395d363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_and_standardize(X, low=0.005, high=0.995, quantiles=True):\n",
    "    if quantiles:\n",
    "        X_clp = np.clip(X, np.quantile(X, low), np.quantile(X, high))\n",
    "    else:\n",
    "        X_clp = np.clip(X, low, high)\n",
    "    X_stdz = (X_clp-np.mean(X_clp))/np.std(X_clp)\n",
    "    \n",
    "    return X_stdz\n",
    "\n",
    "class destripeDataSet(Dataset):\n",
    "    def __init__(self, path, l, normalize=True, logTransform=False):\n",
    "        \n",
    "        # TODO: add this to standalone destripe\n",
    "        from tomoSegmentPipeline.utils.common import read_array\n",
    "        \n",
    "        # data is originally in ZYX form\n",
    "        image_data = read_array(path)\n",
    "        # we set data in YZX form\n",
    "        image_data = image_data.transpose(1, 0, 2)\n",
    "        \n",
    "        if logTransform:\n",
    "            image_data = np.log10(image_data)  \n",
    "            \n",
    "        if normalize:\n",
    "            image_data = Parallel(n_jobs=1)(delayed(clip_and_standardize)(xz_plane) for xz_plane in image_data)\n",
    "            image_data = np.array(image_data)\n",
    "            # image_data = image_data - image_data.min()\n",
    "            \n",
    "        fft_img = np.array([np.fft.fftshift(np.fft.fft2(xz_plane)) for xz_plane in image_data]) # just run fft on the image information\n",
    "        \n",
    "        logPower_data = np.log(np.abs(fft_img)**2)\n",
    "        logPower_data = Parallel(n_jobs=1)(delayed(clip_and_standardize)(xz_plane, low=0.001, high=0.999) for xz_plane in logPower_data)\n",
    "        logPower_data = np.array(logPower_data)\n",
    "        \n",
    "        # all image data is in the form: YZX\n",
    "        # data[:, 0, :, :] = image\n",
    "        # data[:, 1, :, :] = outlier mask\n",
    "        # data[:, 2, :, :] = weights\n",
    "        data = image_data[:, np.newaxis, :, :]\n",
    "        \n",
    "        # data = io.loadmat('Data/simu-small-constant.mat')['datas'].transpose(2, 0, 1)[:, np.newaxis, :, :]\n",
    "        #data = np.repeat(io.loadmat('Data/oneround.mat')['data'][np.newaxis, np.newaxis, :, :], 3, axis=0)          \n",
    "\n",
    "        # get outliers according to the power criterion \n",
    "        outlier_mask = np.array([(xz_plane<np.quantile(xz_plane, 0.95)).astype(int) for xz_plane in logPower_data])\n",
    "        outlier_mask = outlier_mask[:, np.newaxis, :, :] # set a consistent shape of the data\n",
    "        \n",
    "        # get proper shape of the weight data\n",
    "        weight_matrix = logPower_data[:, np.newaxis, :, :]\n",
    "\n",
    "        # concatenate stuff\n",
    "        data = np.concatenate((data, outlier_mask), 1)  \n",
    "        data = np.concatenate((data, weight_matrix), 1)   \n",
    "        \n",
    "        # why? Only for testing?\n",
    "        data = data[l[0]:l[1], :, :, :]\n",
    "        \n",
    "        self.x_data = torch.from_numpy(data).float()\n",
    "        self.y_data = torch.from_numpy(np.zeros((3, 1))).float()\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x_data.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "937d0835-5fcd-454c-8ec5-b8c95927bd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 13s ± 789 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "cet_path = os.path.join(ISONET_PATH, 'RAW_dataset/RAW_allTomos_deconv/tomo10.mrc')    \n",
    "\n",
    "tmp = destripeDataSet(path = cet_path, l = [0, 1])\n",
    "\n",
    "# print(tmp.x_data.size())\n",
    "# print(tmp.y_data.size())\n",
    "# print(tmp.y_data)\n",
    "# plt.imshow(tmp.x_data[-1, 0, :, :])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b8c6123e-cac1-492c-8d94-97b6326e8b04",
   "metadata": {},
   "source": [
    "# n_jobs = 6\n",
    "2min 23s ± 17.7 s per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2207078f-8a46-4900-9f0a-8839a826294a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
