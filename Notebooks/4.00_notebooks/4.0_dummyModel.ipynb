{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7754935a-06bf-4391-b99d-c48eed00d9f0",
   "metadata": {},
   "source": [
    "I want to construct a model which satisfies as many sanity checks as I can think of to allow me to be sure that my progress is solid.\n",
    "\n",
    "The main problem here is that I found weird values in the validation set in 3.19: predicting directly on the validation set gives me very different results compared to the values from the logs, and it should be the same. I don't know if this is because of the (wrong) data augmentation I implemented in the validation set, the mutliGPU training or some other error along the way.\n",
    "\n",
    "Also, I can see many instances where the dice score for class 1 is zero when predicting on the validation data set\n",
    "\n",
    "First I will run the sanity checks with 1 GPU only and then see how they behave with multiple GPUs\n",
    "\n",
    "1. Run model for 1 epoch using one patch for training and one patch for validation. Check:\n",
    "    - The logged validation loss corresponds to the validation loss I get by predicting the validation dataset using the trained model\n",
    "    - Same for the train loss\n",
    "    - Check if there are values with dice score for class 1 equal to zero in training or validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff2ceb0a-2321-43eb-9e78-e5cfbc6897a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomoSegmentPipeline import dataloader as dl\n",
    "from tomoSegmentPipeline.utils import setup\n",
    "from tomoSegmentPipeline.dataloader import to_categorical, transpose_to_channels_first, tomoSegment_dummyDataset, tomoSegment_dataset\n",
    "from tomoSegmentPipeline.training import Train\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "import os\n",
    "\n",
    "PARENT_PATH = setup.PARENT_PATH\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from tomoSegmentPipeline.showcaseResults import (predict_fullTomogram, load_model, load_tomoData, Tversky_index, Tversky_loss, Tversky1_loss,\n",
    "                                        fullTomogram_modelComparison, make_comparison_plot, write_comparison_gif, save_classPred)\n",
    "\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "\n",
    "\n",
    "val_tomos = ['tomo32', 'tomo10']\n",
    "concat_val_ids = sorted([s.replace('tomo', '') for s in val_tomos])\n",
    "concat_val_ids = '-'.join(concat_val_ids)\n",
    "\n",
    "test_tomos = ['tomo38', 'tomo04']\n",
    "concat_test_ids = sorted([s.replace('tomo', '') for s in test_tomos])\n",
    "concat_test_ids = '-'.join(concat_test_ids)\n",
    "\n",
    "\n",
    "input_type = 'cryoCARE+isoNET'\n",
    "\n",
    "train_tomos = ['tomo02', 'tomo03', 'tomo17']\n",
    "\n",
    "concat_train_ids = sorted([s.replace('tomo', '') for s in train_tomos])\n",
    "concat_train_ids = '-'.join(concat_train_ids)\n",
    "\n",
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba17a43e-8892-444c-bb63-cdc54cb27670",
   "metadata": {},
   "source": [
    "# Single GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6ca18b-626c-46d7-aa5f-d629325a3f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "Missing logger folder: /home/haicu/jeronimo.carvajal/Thesis/data/model_logs/sanity_checks/logs/1EpochBaseline/cryoCARE+isoNET/\n",
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name    | Type          | Params\n",
      "------------------------------------------\n",
      "0 | loss_fn | Tversky1_loss | 0     \n",
      "1 | layer1  | Sequential    | 28.6 K\n",
      "2 | layer2  | Sequential    | 103 K \n",
      "3 | layer3  | Sequential    | 558 K \n",
      "4 | layer4  | Sequential    | 288 K \n",
      "5 | layer5  | Sequential    | 96.9 K\n",
      "------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.304     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Ncl\":           2\n",
      "\"loss_fn\":       Tversky1_loss()\n",
      "\"lr\":            0.0001\n",
      "\"pretrain_type\": None\n",
      "\"weight_decay\":  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric hp/val_loss improved. New best score: 0.770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at:  /home/haicu/jeronimo.carvajal/Thesis/data/model_logs/sanity_checks/logs/1EpochBaseline/cryoCARE+isoNET/version_0/Baseline_ep1_in84_lr0.000100_0.model\n"
     ]
    }
   ],
   "source": [
    "chkpnt = None\n",
    "\n",
    "tb_logdir = os.path.join(PARENT_PATH, 'data/model_logs/sanity_checks/logs/1EpochBaseline/%s/' %input_type)\n",
    "model_name = 'Baseline'\n",
    "\n",
    "epochs = 1\n",
    "Ncl = 2\n",
    "dim_in = 84\n",
    "lr = 1e-4\n",
    "weight_decay = 0\n",
    "Lrnd = 18\n",
    "augment_data = True\n",
    "batch_size = 22\n",
    "pretrained_model = None\n",
    "\n",
    "trainer = Train(Ncl=Ncl, dim_in=dim_in, lr=lr, weight_decay=weight_decay, Lrnd=Lrnd, tensorboard_logdir=tb_logdir,\n",
    "model_name=model_name, augment_data=augment_data, \n",
    "batch_size=batch_size, epochs=epochs, pretrained_model=pretrained_model)\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "        monitor='hp/val_loss',\n",
    "        min_delta=1e-4,\n",
    "        patience=100,\n",
    "        verbose=True,\n",
    "        mode='min'\n",
    "        )\n",
    "\n",
    "trainer = trainer.launch(train_tomos, val_tomos, input_type=input_type, num_gpus=1, accelerator=None,\n",
    "                         num_workers=1, resume_from_checkpoint=chkpnt, train_callbacks=[early_stop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e6714a7-4e83-495a-a38c-33e3d14493b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model_file</th>\n",
       "      <th>input_type</th>\n",
       "      <th>epochs</th>\n",
       "      <th>patch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>version</th>\n",
       "      <th>best_val_loss_epoch</th>\n",
       "      <th>associated_val_class1_dice</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>/home/haicu/jeronimo.carvajal/Thesis/data/mode...</td>\n",
       "      <td>cryoCARE+isoNET</td>\n",
       "      <td>1 out of 1</td>\n",
       "      <td>in84</td>\n",
       "      <td>lr0.000100</td>\n",
       "      <td>v0</td>\n",
       "      <td>0.76955</td>\n",
       "      <td>0.23045</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name                                         model_file  \\\n",
       "0  Baseline  /home/haicu/jeronimo.carvajal/Thesis/data/mode...   \n",
       "\n",
       "        input_type      epochs patch_size          lr version  \\\n",
       "0  cryoCARE+isoNET  1 out of 1       in84  lr0.000100      v0   \n",
       "\n",
       "   best_val_loss_epoch  associated_val_class1_dice  batch_size  \n",
       "0              0.76955                     0.23045          22  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir_path = '/home/haicu/jeronimo.carvajal/Thesis/data/model_logs/sanity_checks/logs/1EpochBaseline/cryoCARE+isoNET/version_0/'\n",
    "\n",
    "model_file = PARENT_PATH+'data/model_logs/sanity_checks/logs/1EpochBaseline/cryoCARE+isoNET/version_0/Baseline_ep1_in84_lr0.000100_0.model'\n",
    "\n",
    "model_file_split = model_file.split('/')\n",
    "\n",
    "model_info = []\n",
    "\n",
    "input_type = model_file_split[-3]\n",
    "\n",
    "name, epochs, patch_size, lr, version = model_file_split[-1].split('_')\n",
    "epochs = int(epochs.replace('ep', ''))\n",
    "version = 'v'+version.replace('.model', '')\n",
    "\n",
    "events_path = glob(os.path.join(logdir_path, 'events.*'))[0]\n",
    "event_acc = EventAccumulator(events_path)\n",
    "event_acc.Reload()\n",
    "\n",
    "_, step_nums, values_valLoss = zip(*event_acc.Scalars('hp/val_loss'))\n",
    "best_val_loss_epoch = np.min(values_valLoss)\n",
    "best_val_loss_epoch_idx = np.argmin(values_valLoss) #index starts count at 0\n",
    "\n",
    "effective_epochs = len(values_valLoss)\n",
    "\n",
    "_, _, values_dice = zip(*event_acc.Scalars('hp/val_dice'))\n",
    "_, _, values_trainLoss = zip(*event_acc.Scalars('hp/train_loss_epoch'))\n",
    "\n",
    "associated_val_class1_dice = float(values_dice[best_val_loss_epoch_idx])\n",
    "associated_train_loss_epoch = float(values_trainLoss[best_val_loss_epoch_idx])\n",
    "\n",
    "epochs_str = \"%i out of %i\" %(effective_epochs, len(values_trainLoss))\n",
    "\n",
    "model_info.append([name, model_file, input_type, epochs_str, patch_size, lr, version, best_val_loss_epoch, associated_val_class1_dice])\n",
    "\n",
    "df_model = pd.DataFrame(model_info, columns=['name', 'model_file', 'input_type', 'epochs', 'patch_size', 'lr', 'version', 'best_val_loss_epoch',\n",
    "                                         'associated_val_class1_dice'])\n",
    "\n",
    "df_model['batch_size'] = 22\n",
    "\n",
    "print(df_model.shape)\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e423a68-5320-46c4-9753-72ef55b23f9d",
   "metadata": {},
   "source": [
    "# Predict using validation DataLoader yields same results as logs: YES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7169e0bd-bfe1-43b7-b2e3-f1fc7d44e528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for cryoCARE+isoNET using Validation DataLoader...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_fn = Tversky1_loss()\n",
    "\n",
    "nCenters_dict = {'in56':4, 'in84':2}\n",
    "\n",
    "dice1_test_bestModels = []\n",
    "\n",
    "for i, row in df_model.iterrows():\n",
    "    model_fileList = [row['model_file']]\n",
    "    n_centers_list = [nCenters_dict[row['patch_size']]]\n",
    "    \n",
    "    input_type = row['input_type']\n",
    "    batch_size = row['batch_size']\n",
    "    dim_in = row['patch_size'].replace('in', '')\n",
    "    dim_in = int(dim_in)\n",
    "    \n",
    "    model = load_model(row['model_file'], Nclass=2)\n",
    "    \n",
    "    paths_valData, paths_valTarget = setup.get_paths(val_tomos, input_type)\n",
    "    \n",
    "    my_dataset = dl.tomoSegment_dataset(paths_valData, paths_valTarget, dim_in=dim_in, Ncl=3, Lrnd=0, augment_data=False)\n",
    "    val_loader = DataLoader(my_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=1)\n",
    "\n",
    "    dice1_avg = []\n",
    "    val_loss_avg = []\n",
    " \n",
    "    print('Predicting for %s using Validation DataLoader...\\n' %input_type)\n",
    "    for patch, target in val_loader:\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(patch)\n",
    "\n",
    "        y_true = target.to('cuda')\n",
    "\n",
    "        dice_by_class = Tversky_index(y_pred, y_true).to('cpu')\n",
    "        dice1_avg.append(float(dice_by_class[1]))\n",
    "\n",
    "        val_loss = loss_fn(y_pred, y_true).to('cpu')\n",
    "        val_loss_avg.append(float(val_loss))\n",
    "\n",
    "    dice1_avg = np.mean(dice1_avg)\n",
    "    avg_loss = np.mean(val_loss_avg)\n",
    "    dice1_test_bestModels.append(np.mean(dice1_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94f96650-5d2d-431b-8831-c27b3d4b5b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model_file</th>\n",
       "      <th>input_type</th>\n",
       "      <th>epochs</th>\n",
       "      <th>patch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>version</th>\n",
       "      <th>best_val_loss_epoch</th>\n",
       "      <th>associated_val_class1_dice</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>loss_val_patches_dataLoader</th>\n",
       "      <th>dice1_val_patches_dataLoader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>/home/haicu/jeronimo.carvajal/Thesis/data/mode...</td>\n",
       "      <td>cryoCARE+isoNET</td>\n",
       "      <td>1 out of 1</td>\n",
       "      <td>in84</td>\n",
       "      <td>lr0.000100</td>\n",
       "      <td>v0</td>\n",
       "      <td>0.76955</td>\n",
       "      <td>0.23045</td>\n",
       "      <td>22</td>\n",
       "      <td>0.770444</td>\n",
       "      <td>0.229556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name                                         model_file  \\\n",
       "0  Baseline  /home/haicu/jeronimo.carvajal/Thesis/data/mode...   \n",
       "\n",
       "        input_type      epochs patch_size          lr version  \\\n",
       "0  cryoCARE+isoNET  1 out of 1       in84  lr0.000100      v0   \n",
       "\n",
       "   best_val_loss_epoch  associated_val_class1_dice  batch_size  \\\n",
       "0              0.76955                     0.23045          22   \n",
       "\n",
       "   loss_val_patches_dataLoader  dice1_val_patches_dataLoader  \n",
       "0                     0.770444                      0.229556  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model['loss_val_patches_dataLoader'] = avg_loss\n",
    "df_model['dice1_val_patches_dataLoader'] = dice1_test_bestModels\n",
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74c5315-a4f6-494b-aee8-b0d1dae8ec73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2e2a10c-fe12-4636-bb53-1bf10d3407db",
   "metadata": {},
   "source": [
    "# Check how much difference there is between predicting using my method: batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60a945b7-7c5e-4976-8985-7e63da60bf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nclass_data = 3\n",
    "Nclass_model = 2\n",
    "z, y, x = 3*[dim_in]\n",
    "\n",
    "loss_fn = Tversky1_loss()\n",
    "\n",
    "dice1_average = []\n",
    "val_loss_avg = []\n",
    "\n",
    "for instance in my_dataset:\n",
    "    patch, target = instance\n",
    "    patch = torch.as_tensor(patch).unsqueeze(0).to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(patch)\n",
    "        \n",
    "    y_true = torch.zeros((1, Nclass_data, z, y, x))\n",
    "    y_true[0, :, :, :, :] = target\n",
    "    y_true = y_true.to('cuda')\n",
    "    \n",
    "    dice_by_class = Tversky_index(y_pred, y_true).to('cpu')\n",
    "    dice1_average.append(float(dice_by_class[1]))\n",
    "\n",
    "    val_loss = loss_fn(y_pred, y_true).to('cpu')\n",
    "    val_loss_avg.append(float(val_loss))\n",
    "\n",
    "# print(val_loss_avg)\n",
    "dice1_average = np.mean(dice1_average)\n",
    "val_loss_avg = np.mean(val_loss_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0e09b2a-8faf-48d4-91e2-79cf3c7d8800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model_file</th>\n",
       "      <th>input_type</th>\n",
       "      <th>epochs</th>\n",
       "      <th>patch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>version</th>\n",
       "      <th>best_val_loss_epoch</th>\n",
       "      <th>associated_val_class1_dice</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>loss_val_patches_dataLoader</th>\n",
       "      <th>dice1_val_patches_dataLoader</th>\n",
       "      <th>loss_val_patches</th>\n",
       "      <th>dice1_val_patches</th>\n",
       "      <th>loss_val_patches_dataLoader_bs1</th>\n",
       "      <th>dice1_val_patches_dataLoader_bs1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>/home/haicu/jeronimo.carvajal/Thesis/data/mode...</td>\n",
       "      <td>cryoCARE+isoNET</td>\n",
       "      <td>1 out of 1</td>\n",
       "      <td>in84</td>\n",
       "      <td>lr0.000100</td>\n",
       "      <td>v0</td>\n",
       "      <td>0.76955</td>\n",
       "      <td>0.23045</td>\n",
       "      <td>22</td>\n",
       "      <td>0.770444</td>\n",
       "      <td>0.229556</td>\n",
       "      <td>0.795742</td>\n",
       "      <td>1.204258</td>\n",
       "      <td>0.795742</td>\n",
       "      <td>0.204258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name                                         model_file  \\\n",
       "0  Baseline  /home/haicu/jeronimo.carvajal/Thesis/data/mode...   \n",
       "\n",
       "        input_type      epochs patch_size          lr version  \\\n",
       "0  cryoCARE+isoNET  1 out of 1       in84  lr0.000100      v0   \n",
       "\n",
       "   best_val_loss_epoch  associated_val_class1_dice  batch_size  \\\n",
       "0              0.76955                     0.23045          22   \n",
       "\n",
       "   loss_val_patches_dataLoader  dice1_val_patches_dataLoader  \\\n",
       "0                     0.770444                      0.229556   \n",
       "\n",
       "   loss_val_patches  dice1_val_patches  loss_val_patches_dataLoader_bs1  \\\n",
       "0          0.795742           1.204258                         0.795742   \n",
       "\n",
       "   dice1_val_patches_dataLoader_bs1  \n",
       "0                          0.204258  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model['loss_val_patches'] = np.mean(val_loss_avg)\n",
    "df_model['dice1_val_patches'] = dice_average\n",
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f3ee400-1efc-4464-8ca6-1462089457ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for cryoCARE+isoNET using Validation DataLoader...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_fn = Tversky1_loss()\n",
    "\n",
    "nCenters_dict = {'in56':4, 'in84':2}\n",
    "\n",
    "dice1_test_bestModels = []\n",
    "\n",
    "for i, row in df_model.iterrows():\n",
    "    model_fileList = [row['model_file']]\n",
    "    n_centers_list = [nCenters_dict[row['patch_size']]]\n",
    "    \n",
    "    input_type = row['input_type']\n",
    "    batch_size = row['batch_size']\n",
    "    dim_in = row['patch_size'].replace('in', '')\n",
    "    dim_in = int(dim_in)\n",
    "    \n",
    "    model = load_model(row['model_file'], Nclass=2)\n",
    "    \n",
    "    paths_valData, paths_valTarget = setup.get_paths(val_tomos, input_type)\n",
    "    \n",
    "    my_dataset = dl.tomoSegment_dataset(paths_valData, paths_valTarget, dim_in=dim_in, Ncl=3, Lrnd=0, augment_data=False)\n",
    "    val_loader = DataLoader(my_dataset, batch_size=1, shuffle=True, pin_memory=True, num_workers=1)\n",
    "\n",
    "    dice1_avg = []\n",
    "    val_loss_avg = []\n",
    " \n",
    "    print('Predicting for %s using Validation DataLoader...\\n' %input_type)\n",
    "    for patch, target in val_loader:\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(patch)\n",
    "\n",
    "        y_true = target.to('cuda')\n",
    "\n",
    "        dice_by_class = Tversky_index(y_pred, y_true).to('cpu')\n",
    "        dice1_avg.append(float(dice_by_class[1]))\n",
    "\n",
    "        val_loss = loss_fn(y_pred, y_true).to('cpu')\n",
    "        val_loss_avg.append(float(val_loss))\n",
    "\n",
    "    dice1_avg = np.mean(dice1_avg)\n",
    "    avg_loss = np.mean(val_loss_avg)\n",
    "    dice1_test_bestModels.append(np.mean(dice1_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780b4674-42a8-46bf-a359-fec4a6d17236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model_file</th>\n",
       "      <th>input_type</th>\n",
       "      <th>epochs</th>\n",
       "      <th>patch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>version</th>\n",
       "      <th>best_val_loss_epoch</th>\n",
       "      <th>associated_val_class1_dice</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>loss_val_patches_dataLoader</th>\n",
       "      <th>dice1_val_patches_dataLoader</th>\n",
       "      <th>loss_val_patches</th>\n",
       "      <th>dice1_val_patches</th>\n",
       "      <th>loss_val_patches_dataLoader_bs1</th>\n",
       "      <th>dice1_val_patches_dataLoader_bs1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>/home/haicu/jeronimo.carvajal/Thesis/data/mode...</td>\n",
       "      <td>cryoCARE+isoNET</td>\n",
       "      <td>1 out of 1</td>\n",
       "      <td>in84</td>\n",
       "      <td>lr0.000100</td>\n",
       "      <td>v0</td>\n",
       "      <td>0.76955</td>\n",
       "      <td>0.23045</td>\n",
       "      <td>22</td>\n",
       "      <td>0.770444</td>\n",
       "      <td>0.229556</td>\n",
       "      <td>0.795742</td>\n",
       "      <td>1.204258</td>\n",
       "      <td>0.795742</td>\n",
       "      <td>0.204258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name                                         model_file  \\\n",
       "0  Baseline  /home/haicu/jeronimo.carvajal/Thesis/data/mode...   \n",
       "\n",
       "        input_type      epochs patch_size          lr version  \\\n",
       "0  cryoCARE+isoNET  1 out of 1       in84  lr0.000100      v0   \n",
       "\n",
       "   best_val_loss_epoch  associated_val_class1_dice  batch_size  \\\n",
       "0              0.76955                     0.23045          22   \n",
       "\n",
       "   loss_val_patches_dataLoader  dice1_val_patches_dataLoader  \\\n",
       "0                     0.770444                      0.229556   \n",
       "\n",
       "   loss_val_patches  dice1_val_patches  loss_val_patches_dataLoader_bs1  \\\n",
       "0          0.795742           1.204258                         0.795742   \n",
       "\n",
       "   dice1_val_patches_dataLoader_bs1  \n",
       "0                          0.204258  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model['loss_val_patches_dataLoader_bs1'] = avg_loss\n",
    "df_model['dice1_val_patches_dataLoader_bs1'] = dice1_test_bestModels\n",
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db0ecc2-772f-488c-ae2c-4f53642f5028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a60d02c2-249a-4ad1-ba9f-939d780f31cc",
   "metadata": {},
   "source": [
    "# Multiple GPU: models_2 folder (not a dummy model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a125182a-4bb9-4997-9f79-06156628b1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model_file</th>\n",
       "      <th>input_type</th>\n",
       "      <th>epochs</th>\n",
       "      <th>patch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>version</th>\n",
       "      <th>best_val_loss_epoch</th>\n",
       "      <th>associated_val_class1_dice</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>/home/haicu/jeronimo.carvajal/Thesis/data/mode...</td>\n",
       "      <td>cryoCARE+isoNET</td>\n",
       "      <td>431 out of 1000</td>\n",
       "      <td>in84</td>\n",
       "      <td>lr0.000100</td>\n",
       "      <td>v0</td>\n",
       "      <td>0.086578</td>\n",
       "      <td>0.913422</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name                                         model_file  \\\n",
       "0  Baseline  /home/haicu/jeronimo.carvajal/Thesis/data/mode...   \n",
       "\n",
       "        input_type           epochs patch_size          lr version  \\\n",
       "0  cryoCARE+isoNET  431 out of 1000       in84  lr0.000100      v0   \n",
       "\n",
       "   best_val_loss_epoch  associated_val_class1_dice  batch_size  \n",
       "0             0.086578                    0.913422          22  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir_path = '/home/haicu/jeronimo.carvajal/Thesis/data/model_logs/models_2/logs/BaselineModel/cryoCARE+isoNET/train02-03-17/version_0/'\n",
    "\n",
    "model_file = PARENT_PATH+'data/model_logs/models_2/logs/BaselineModel/cryoCARE+isoNET/train02-03-17/version_0/Baseline_ep1000_in84_lr0.000100_0.model'\n",
    "\n",
    "model_file_split = model_file.split('/')\n",
    "\n",
    "model_info = []\n",
    "\n",
    "input_type = model_file_split[-4]\n",
    "\n",
    "name, epochs, patch_size, lr, version = model_file_split[-1].split('_')\n",
    "epochs = int(epochs.replace('ep', ''))\n",
    "version = 'v'+version.replace('.model', '')\n",
    "\n",
    "events_path = glob(os.path.join(logdir_path, 'events.*'))[0]\n",
    "event_acc = EventAccumulator(events_path)\n",
    "event_acc.Reload()\n",
    "\n",
    "_, step_nums, values_valLoss = zip(*event_acc.Scalars('hp/val_loss'))\n",
    "best_val_loss_epoch = np.min(values_valLoss)\n",
    "best_val_loss_epoch_idx = np.argmin(values_valLoss) #index starts count at 0\n",
    "\n",
    "effective_epochs = len(values_valLoss)\n",
    "\n",
    "_, _, values_dice = zip(*event_acc.Scalars('hp/val_dice'))\n",
    "_, _, values_trainLoss = zip(*event_acc.Scalars('hp/train_loss_epoch'))\n",
    "\n",
    "associated_val_class1_dice = float(values_dice[best_val_loss_epoch_idx])\n",
    "associated_train_loss_epoch = float(values_trainLoss[best_val_loss_epoch_idx])\n",
    "\n",
    "epochs_str = \"%i out of %i\" %(effective_epochs, 1000)\n",
    "\n",
    "model_info.append([name, model_file, input_type, epochs_str, patch_size, lr, version, best_val_loss_epoch, associated_val_class1_dice])\n",
    "\n",
    "df_model = pd.DataFrame(model_info, columns=['name', 'model_file', 'input_type', 'epochs', 'patch_size', 'lr', 'version', 'best_val_loss_epoch',\n",
    "                                         'associated_val_class1_dice'])\n",
    "\n",
    "df_model['batch_size'] = 22\n",
    "\n",
    "print(df_model.shape)\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253b58d2-ce1d-4cd5-a881-b9aded77a6e2",
   "metadata": {},
   "source": [
    "# Predict using validation DataLoader yields same results as logs: YES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4046aa45-aba6-4cd5-86a2-91c5ff4f1702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for cryoCARE+isoNET using Validation DataLoader...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_fn = Tversky1_loss()\n",
    "\n",
    "nCenters_dict = {'in56':4, 'in84':2}\n",
    "\n",
    "dice1_test_bestModels = []\n",
    "\n",
    "for i, row in df_model.iterrows():\n",
    "    model_fileList = [row['model_file']]\n",
    "    n_centers_list = [nCenters_dict[row['patch_size']]]\n",
    "    \n",
    "    input_type = row['input_type']\n",
    "    batch_size = row['batch_size']\n",
    "    dim_in = row['patch_size'].replace('in', '')\n",
    "    dim_in = int(dim_in)\n",
    "    \n",
    "    model = load_model(row['model_file'], Nclass=2)\n",
    "    \n",
    "    paths_valData, paths_valTarget = setup.get_paths(val_tomos, input_type)\n",
    "    \n",
    "    my_dataset = dl.tomoSegment_dataset(paths_valData, paths_valTarget, dim_in=dim_in, Ncl=3, Lrnd=0, augment_data=False)\n",
    "    val_loader = DataLoader(my_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=1)\n",
    "\n",
    "    dice1_avg = []\n",
    "    val_loss_avg = []\n",
    " \n",
    "    print('Predicting for %s using Validation DataLoader...\\n' %input_type)\n",
    "    for patch, target in val_loader:\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(patch)\n",
    "\n",
    "        y_true = target.to('cuda')\n",
    "\n",
    "        dice_by_class = Tversky_index(y_pred, y_true).to('cpu')\n",
    "        dice1_avg.append(float(dice_by_class[1]))\n",
    "\n",
    "        val_loss = loss_fn(y_pred, y_true).to('cpu')\n",
    "        val_loss_avg.append(float(val_loss))\n",
    "\n",
    "    dice1_avg = np.mean(dice1_avg)\n",
    "    avg_loss = np.mean(val_loss_avg)\n",
    "    dice1_test_bestModels.append(np.mean(dice1_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4538a641-16f9-4912-864e-7f164070217b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model_file</th>\n",
       "      <th>input_type</th>\n",
       "      <th>epochs</th>\n",
       "      <th>patch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>version</th>\n",
       "      <th>best_val_loss_epoch</th>\n",
       "      <th>associated_val_class1_dice</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>loss_val_patches_dataLoader</th>\n",
       "      <th>dice1_val_patches_dataLoader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>/home/haicu/jeronimo.carvajal/Thesis/data/mode...</td>\n",
       "      <td>cryoCARE+isoNET</td>\n",
       "      <td>431 out of 1000</td>\n",
       "      <td>in84</td>\n",
       "      <td>lr0.000100</td>\n",
       "      <td>v0</td>\n",
       "      <td>0.086578</td>\n",
       "      <td>0.913422</td>\n",
       "      <td>22</td>\n",
       "      <td>0.085344</td>\n",
       "      <td>0.914656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name                                         model_file  \\\n",
       "0  Baseline  /home/haicu/jeronimo.carvajal/Thesis/data/mode...   \n",
       "\n",
       "        input_type           epochs patch_size          lr version  \\\n",
       "0  cryoCARE+isoNET  431 out of 1000       in84  lr0.000100      v0   \n",
       "\n",
       "   best_val_loss_epoch  associated_val_class1_dice  batch_size  \\\n",
       "0             0.086578                    0.913422          22   \n",
       "\n",
       "   loss_val_patches_dataLoader  dice1_val_patches_dataLoader  \n",
       "0                     0.085344                      0.914656  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model['loss_val_patches_dataLoader'] = avg_loss\n",
    "df_model['dice1_val_patches_dataLoader'] = dice1_test_bestModels\n",
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a82a36d-12fc-4e63-b7ee-0d562299e22f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
