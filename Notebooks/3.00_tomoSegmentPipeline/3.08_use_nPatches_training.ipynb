{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15244bd0-49ef-48d7-8546-7808760abec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tomoSegmentPipeline.showcaseResults import (predict_fullTomogram, load_model, load_tomoData, Tversky_index,\n",
    "                                        fullTomogram_modelComparison, make_comparison_plot, write_comparison_gif, save_classPred)\n",
    "\n",
    "from tomoSegmentPipeline.losses import Tversky_loss\n",
    "from tomoSegmentPipeline.utils.common import read_array\n",
    "import tomoSegmentPipeline.dataloader as dl\n",
    "from tomoSegmentPipeline.utils import setup\n",
    "from tomoSegmentPipeline.dataloader import to_categorical, transpose_to_channels_first\n",
    "from tomoSegmentPipeline.trainWrapper import make_trainer\n",
    "\n",
    "PARENT_PATH = setup.PARENT_PATH\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import mrcfile\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from glob import glob\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "train_tomos = ['tomo02', 'tomo03', 'tomo17']\n",
    "concat_train_ids = sorted([s.replace('tomo', '') for s in train_tomos])\n",
    "concat_train_ids = '-'.join(concat_train_ids)\n",
    "\n",
    "val_tomos = ['tomo32', 'tomo10']\n",
    "concat_val_ids = sorted([s.replace('tomo', '') for s in val_tomos])\n",
    "concat_val_ids = '-'.join(concat_val_ids)\n",
    "\n",
    "test_tomos = ['tomo38', 'tomo04']\n",
    "concat_test_ids = sorted([s.replace('tomo', '') for s in test_tomos])\n",
    "concat_test_ids = '-'.join(concat_test_ids)\n",
    "\n",
    "\n",
    "paths_trainData, paths_trainTarget = setup.get_paths(train_tomos, 'cryoCARE')\n",
    "paths_valData, paths_valTarget = setup.get_paths(val_tomos, 'cryoCARE')\n",
    "paths_testData, paths_testTarget = setup.get_paths(test_tomos, 'cryoCARE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ada233-8a1f-4870-a671-cdbf900eba71",
   "metadata": {},
   "source": [
    "# Subset patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be124d29-4815-4460-b609-d5be12a30133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paths_trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98e24771-1a22-49e4-b13b-3728a041ec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2)\n",
    "nPatches_train = 6\n",
    "rand_idxs = random.sample(range(len(paths_trainData)), nPatches_train)\n",
    "paths_trainData_sub = sorted(list(np.array(paths_trainData)[rand_idxs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8f80f86-8c96-44b8-aa0e-66388b0a3585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random indices used for training:  [8, 18, 27, 25]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['/home/haicu/jeronimo.carvajal/Thesis/data/nnUnet/Task143_cryoET7/imagesTr/tomo02_patch021_0000.nii.gz',\n",
       "  '/home/haicu/jeronimo.carvajal/Thesis/data/nnUnet/Task143_cryoET7/imagesTr/tomo03_patch022_0000.nii.gz',\n",
       "  '/home/haicu/jeronimo.carvajal/Thesis/data/nnUnet/Task143_cryoET7/imagesTr/tomo17_patch009_0000.nii.gz',\n",
       "  '/home/haicu/jeronimo.carvajal/Thesis/data/nnUnet/Task143_cryoET7/imagesTr/tomo17_patch006_0000.nii.gz'],\n",
       " ['/home/haicu/jeronimo.carvajal/Thesis/data/nnUnet/Task143_cryoET7/labelsTr/tomo02_patch021.nii.gz',\n",
       "  '/home/haicu/jeronimo.carvajal/Thesis/data/nnUnet/Task143_cryoET7/labelsTr/tomo03_patch022.nii.gz',\n",
       "  '/home/haicu/jeronimo.carvajal/Thesis/data/nnUnet/Task143_cryoET7/labelsTr/tomo17_patch009.nii.gz',\n",
       "  '/home/haicu/jeronimo.carvajal/Thesis/data/nnUnet/Task143_cryoET7/labelsTr/tomo17_patch006.nii.gz'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nPatches_training = 4\n",
    "random.seed(1)\n",
    "random_indices = random.sample(range(len(paths_trainData)), len(paths_trainData))[0:nPatches_training]\n",
    "print('Random indices used for training: ', random_indices)\n",
    "paths_trainData_sub = list(np.array(paths_trainData)[random_indices])\n",
    "paths_trainTarget_sub = list(np.array(paths_trainTarget)[random_indices])\n",
    "\n",
    "paths_trainData_sub, paths_trainTarget_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0cb1ef3a-4adb-47b6-b7e7-1fd772fab59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'tomo02': 3\\\\, 'tomo03': 1\\\\, 'tomo17': 2\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tomo_counts = [x.split('/')[-1].split('_')[0] for x in paths_trainData_sub]\n",
    "tomo_counts = np.unique(tomo_counts, return_counts=True)\n",
    "tomo_counts = str(dict(zip(*tomo_counts)))[1:-1]\n",
    "tomo_counts.replace(',', '\\,')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04213817-da70-4456-be92-6d3386574d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tomo02', 'tomo02', 'tomo02', 'tomo03', 'tomo17', 'tomo17']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip([x.split('/')[-1].split('_')[0] for x in paths_trainData_sub]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e43c0b3-d003-43c3-af82-86105e7a8cc0",
   "metadata": {},
   "source": [
    "# Scratchpad models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bd53343d-5981-4912-8c82-286f62b0f4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name    | Type         | Params\n",
      "-----------------------------------------\n",
      "0 | loss_fn | Tversky_loss | 0     \n",
      "1 | layer1  | Sequential   | 28.6 K\n",
      "2 | layer2  | Sequential   | 103 K \n",
      "3 | layer3  | Sequential   | 558 K \n",
      "4 | layer4  | Sequential   | 288 K \n",
      "5 | layer5  | Sequential   | 96.9 K\n",
      "-----------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.304     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Ncl\":           2\n",
      "\"loss_fn\":       Tversky_loss()\n",
      "\"lr\":            3e-05\n",
      "\"pretrain_type\": None\n",
      "\"weight_decay\":  0\n",
      "Saving model at:  /home/haicu/jeronimo.carvajal/Thesis/models_scratchpad/logs/BaselineModel/train02-03-17/version_3/3.00_Baseline_ep3_in84_lr0.000030_3.model\n",
      "\n",
      "Writing to modelSummary...\n",
      "Opening ModelSummary file...\n",
      "ModelSummary file exists, appending current model data...\n"
     ]
    }
   ],
   "source": [
    "from tomoSegmentPipeline import dataloader as dl\n",
    "from tomoSegmentPipeline.utils import setup\n",
    "from tomoSegmentPipeline.dataloader import to_categorical, transpose_to_channels_first, tomoSegment_dummyDataset, tomoSegment_dataset\n",
    "from tomoSegmentPipeline.training import Train\n",
    "import os\n",
    "\n",
    "PARENT_PATH = setup.PARENT_PATH\n",
    "\n",
    "import torch\n",
    "\n",
    "val_tomos = ['tomo32', 'tomo10']\n",
    "concat_val_ids = sorted([s.replace('tomo', '') for s in val_tomos])\n",
    "concat_val_ids = '-'.join(concat_val_ids)\n",
    "\n",
    "test_tomos = ['tomo38', 'tomo04']\n",
    "concat_test_ids = sorted([s.replace('tomo', '') for s in test_tomos])\n",
    "concat_test_ids = '-'.join(concat_test_ids)\n",
    "\n",
    "\n",
    "training_schedule = [['tomo02', 'tomo03', 'tomo17'], ['tomo02'], ['tomo03'], ['tomo17']]\n",
    "# training_schedule = [['tomo02'], ['tomo03'], ['tomo17']]\n",
    "\n",
    "\n",
    "for train_tomos in training_schedule:\n",
    "    concat_train_ids = sorted([s.replace('tomo', '') for s in train_tomos])\n",
    "    concat_train_ids = '-'.join(concat_train_ids)\n",
    "\n",
    "    chkpnt = None\n",
    "\n",
    "    if len(train_tomos)==1:\n",
    "        tb_logdir = os.path.join(PARENT_PATH, 'models_scratchpad/logs/LowBaselineModel/train%s' %concat_train_ids)\n",
    "        model_name = '3.00_lowBaseline'\n",
    "        epochs = 3\n",
    "\n",
    "        # chkpnt = os.path.join(tb_logdir, 'version_4/checkpoints/epoch=799-step=1599.ckpt')\n",
    "        # epochs += 200\n",
    "\n",
    "    elif len(train_tomos)==3:\n",
    "        tb_logdir = os.path.join(PARENT_PATH, 'models_scratchpad/logs/BaselineModel/train%s' %concat_train_ids)\n",
    "        model_name = '3.00_Baseline'\n",
    "        epochs = 3\n",
    "\n",
    "        # chkpnt = os.path.join(tb_logdir, 'version_10/checkpoints/epoch=699-step=3499.ckpt')\n",
    "        # epochs += 200\n",
    "\n",
    "    \n",
    "    Ncl = 2\n",
    "    dim_in = 84\n",
    "    lr = 3e-5\n",
    "    weight_decay = 0\n",
    "    Lrnd = 18\n",
    "    augment_data = True\n",
    "    batch_size = 24\n",
    "    nPatches_training = 5\n",
    "    pretrained_model = None\n",
    "\n",
    "    trainer = Train(Ncl=Ncl, dim_in=dim_in, lr=lr, weight_decay=weight_decay, Lrnd=Lrnd, tensorboard_logdir=tb_logdir,\n",
    "                    model_name=model_name, augment_data=augment_data, batch_size=batch_size, epochs=epochs,\n",
    "                    pretrained_model=pretrained_model)\n",
    "\n",
    "    trainer.launch(train_tomos, val_tomos, input_type='cryoCARE', num_gpus=3, accelerator='dp',\n",
    "                   num_workers=1, resume_from_checkpoint=chkpnt,  nPatches_training=nPatches_training)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be6668f3-1233-40f9-a4fc-faed19133f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "5\n",
      "7\n",
      "9\n",
      "11\n",
      "13\n",
      "15\n",
      "17\n",
      "19\n",
      "21\n",
      "23\n",
      "25\n",
      "27\n",
      "29\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "for nPatches in range(1, 33, 2):\n",
    "    print(nPatches)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
