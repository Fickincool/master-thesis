# Notebooks v6

Self2self denoising with dropout for cryoET. Based on https://openaccess.thecvf.com/content_CVPR_2020/papers/Quan_Self2Self_With_Dropout_Learning_Self-Supervised_Denoising_From_Single_Image_CVPR_2020_paper.pdf

## 6.00 Dataloader

The dataset consists of subtomograms of shape [m, s, s, s] where m is the number of Bernoulli samples and s is the subtomogram side length.

*... we do not need to create the whole dataset of Bernoulli sampled instances in advance but just enable dropout without energy scaling on the input layer and pass the copies of the input noisy images to the NN at each iteration.* 

Think how to implement:
*... data augmentation is also used in the implementation by flipping the input image horizontally, vertically and diagonally.*

## 6.01 Model+loss

For the model, we use an input tensor of shape [batch_size, bernoulli_sample_size, subtomo_side, subtomo_side, subtomo_side] and it just follows the structure of the self2self paper, but maybe I could use a slightly smaller model.

The loss is currently the MSEloss summed over all dimensions, but only taking into account the points that were initially dropped out and predicted by the network. We compare the prediction against the real values of the pixels in the (1-bernoulli_mask) set of the tomogram.

## 6.02 Training

I don't understand why there's a sudden drop in the training loss at the end of each training step, regardless of wether I shuffle the batches or not in the dataloader.

Now I'm thinking it is because the last batch has half of the 