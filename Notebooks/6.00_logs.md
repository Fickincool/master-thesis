# Notebooks v6

Self2self denoising with dropout for cryoET. Based on https://openaccess.thecvf.com/content_CVPR_2020/papers/Quan_Self2Self_With_Dropout_Learning_Self-Supervised_Denoising_From_Single_Image_CVPR_2020_paper.pdf

## 6.00 Dataloader

The dataset consists of subtomograms of shape [m, s, s, s] where m is the number of Bernoulli samples and s is the subtomogram side length.

*... we do not need to create the whole dataset of Bernoulli sampled instances in advance but just enable dropout without energy scaling on the input layer and pass the copies of the input noisy images to the NN at each iteration.* 

Think how to implement:
*... data augmentation is also used in the implementation by flipping the input image horizontally, vertically and diagonally.*

## 6.01 Model+loss

For the model, we use an input tensor of shape [batch_size, bernoulli_sample_size, subtomo_side, subtomo_side, subtomo_side] and it just follows the structure of the self2self paper, but maybe I could use a slightly smaller model.

~~The loss is currently the MSEloss summed over all dimensions, but only taking into account the points that were initially dropped out and predicted by the network. We compare the prediction against the real values of the pixels in the (1-bernoulli_mask) set of the tomogram.~~

The loss is the L2 norm across pixel values that were masked and predicted by the network, then we sum that along bernoulli samples and finally take the average over batches to prevent unwanted effects of incomplete batches that appear when just summing.

## 6.02 Training

I don't understand why there's a sudden drop in the training loss at the end of each training step, regardless of wether I shuffle the batches or not in the dataloader.

Now I'm thinking it is because the last batch has half of the batched values (4 instead of 8) due to the size of the dataset (500).

**The above was the problem.**

## 6.03 Prediction

The network is not denoising the raw tomogram. 

I think the problem might be that it is wrong to set up the number of channels to be corresponding to the number of Bernoulli tomogram samples, since then I get additional weights and biases that are optimized for the samples, which is not what I want. I want a set of weights and biases for the image only, which has one channel, and then I want to take several Bernoulli samples in order to compute the loss on the network predicted, but originally missing pixels.

## Things to try next

- Volumetric blind spots âœ“
- Use only certain patches for training
- Modify the loss to include sparsity components (Total variation)
- Train using deconvolved tomogram, or a mixture of the raw and deconvolved
- Include data augmentation